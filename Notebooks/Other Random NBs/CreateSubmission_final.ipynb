{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir( \"../\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import optuna\n",
    "\n",
    "# Replace the following with your MySQL database connection details\n",
    "host = \"db-mysql-nyc3-14396-do-user-15539286-0.c.db.ondigitalocean.com\"\n",
    "port = 25060\n",
    "database_name = \"recsys_optuna\"\n",
    "username = \"doadmin\"\n",
    "password = \"AVNS_EIQ1D-GbDGJWZPsN3Mt\"\n",
    "\n",
    "# Create an SQLAlchemy engine\n",
    "mysql_url = f\"mysql+pymysql://{username}:{password}@{host}:{port}/{database_name}\"\n",
    "storage = optuna.storages.RDBStorage(url=mysql_url)\n",
    "\n",
    "rp3_study = optuna.load_study(study_name=\"RP3_Hybrid_last\", storage=storage)\n",
    "p3_study = optuna.load_study(study_name=\"P3_Hybrid_last\", storage=storage)\n",
    "slim_study = optuna.load_study(study_name=\"SLIM_Hybrid_last\", storage=storage)\n",
    "knn_study = optuna.load_study(study_name=\"KNN_Hybrid_last\", storage=storage)\n",
    "\n",
    "hybrid_study = optuna.load_study(study_name=\"LINEAR_TOPPOP_Hybrid_last\", storage=storage)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>UserID</th>\n",
       "      <th>ItemID</th>\n",
       "      <th>Interaction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>15</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>16</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>133</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>161</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>187</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>478724</th>\n",
       "      <td>13024</td>\n",
       "      <td>13605</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>478725</th>\n",
       "      <td>13024</td>\n",
       "      <td>13823</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>478726</th>\n",
       "      <td>13024</td>\n",
       "      <td>15122</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>478727</th>\n",
       "      <td>13024</td>\n",
       "      <td>18185</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>478728</th>\n",
       "      <td>13024</td>\n",
       "      <td>20014</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>478729 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        UserID  ItemID  Interaction\n",
       "0            1      15          1.0\n",
       "1            1      16          1.0\n",
       "2            1     133          1.0\n",
       "3            1     161          1.0\n",
       "4            1     187          1.0\n",
       "...        ...     ...          ...\n",
       "478724   13024   13605          1.0\n",
       "478725   13024   13823          1.0\n",
       "478726   13024   15122          1.0\n",
       "478727   13024   18185          1.0\n",
       "478728   13024   20014          1.0\n",
       "\n",
       "[478729 rows x 3 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "path = \"Dataset/data_train.csv\"\n",
    "df = pd.read_csv(filepath_or_buffer=path,\n",
    "                               sep=\",\",\n",
    "                               header=1,\n",
    "                               engine='python',\n",
    "                               names=['UserID', 'ItemID', 'Interaction'])\n",
    "\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_users = pd.read_csv(\"Dataset/data_target_users_test.csv\")\n",
    "target_users.columns = [\"UserID\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of users: 12638, Number of Items: 22222, Min rating: 0.0, Max rating: 1.0\n"
     ]
    }
   ],
   "source": [
    "user_ids = df[\"UserID\"].unique().tolist()\n",
    "user2user_encoded = {x: i for i, x in enumerate(user_ids)}\n",
    "userencoded2user = {i: x for i, x in enumerate(user_ids)}\n",
    "item_ids = df[\"ItemID\"].unique().tolist()\n",
    "item2item_encoded = {x: i for i, x in enumerate(item_ids)}\n",
    "item_encoded2item = {i: x for i, x in enumerate(item_ids)}\n",
    "df[\"User\"] = df[\"UserID\"].map(user2user_encoded)\n",
    "df[\"Item\"] = df[\"ItemID\"].map(item2item_encoded)\n",
    "\n",
    "num_users = len(user2user_encoded)\n",
    "num_items = len(item_encoded2item)\n",
    "df[\"Interaction\"] = df[\"Interaction\"].values.astype(np.float32)\n",
    "\n",
    "# min and max ratings will be used to normalize the ratings later\n",
    "min_rating = 0.0\n",
    "max_rating = max(df[\"Interaction\"])\n",
    "\n",
    "print(\n",
    "    \"Number of users: {}, Number of Items: {}, Min rating: {}, Max rating: {}\".format(\n",
    "        num_users, num_items, min_rating, max_rating\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_score, KFold\n",
    "import numpy as np\n",
    "import scipy.sparse as sps\n",
    "from Data_manager.split_functions.split_train_validation_random_holdout import split_train_in_two_percentage_global_sample\n",
    "\n",
    "urm_all = sps.coo_matrix((df[\"Interaction\"].values, \n",
    "                          (df[\"User\"].values, df[\"Item\"].values)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "userId_unique = df[\"UserID\"].unique()\n",
    "itemId_unique = df[\"ItemID\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_users = len(userId_unique)\n",
    "num_items = len(itemId_unique)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-01-09 23:33:41.229654: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2024-01-09 23:33:41.229686: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n"
     ]
    }
   ],
   "source": [
    "from Recommenders.Recommender_import_list import *\n",
    "from Recommenders.KNN.ItemKNNSimilarityHybridRecommender import ItemKNNSimilarityHybridRecommender\n",
    "from Recommenders.Hybrid.GeneralizedLinearHybridRecommenderCold import GeneralizedLinearHybridRecommenderCold\n",
    "from Recommenders.MatrixFactorization.ImplicitIALSRecommender import ImplicitALSRecommender"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'alpha': 0.0010318988432401724, 'l1_ratio': 0.11924623884276588, 'topK': 8529}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "alphas = [hybrid_study.best_params['w_slim'], hybrid_study.best_params['w_rp3'], hybrid_study.best_params['w_p3'], hybrid_study.best_params['w_knn'], hybrid_study.best_params['w_top']]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RP3betaRecommender: Similarity column 22222 (100.0%), 4536.92 column/sec. Elapsed time 4.90 sec\n"
     ]
    }
   ],
   "source": [
    "slim = MultiThreadSLIM_SLIMElasticNetRecommender(urm_all)\n",
    "slim.fit(workers=8, **slim_study.best_params)\n",
    "\n",
    "rp3 = RP3betaRecommender(urm_all)\n",
    "rp3.fit(**rp3_study.best_params)\n",
    "\n",
    "p3 = P3alphaRecommender(urm_all)\n",
    "p3.fit(**p3_study.best_params)\n",
    "\n",
    "knn = ItemKNNCFRecommender(urm_all)\n",
    "knn.fit(**knn_study.best_params)\n",
    "\n",
    "top = TopPop(urm_all)\n",
    "top.fit()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Recommenders.Hybrid.GeneralizedLinearCoupleHybridRecommender import GeneralizedLinearCoupleHybridRecommender\n",
    "\n",
    "hybrid = GeneralizedLinearHybridRecommender(urm_all, recommenders=[slim, rp3, p3, knn, top])\n",
    "hybrid.fit(alphas=alphas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[    1     2     3 ... 13022 13023 13024]\n"
     ]
    }
   ],
   "source": [
    "item_popularity_encoded = np.ediff1d(urm_all.tocsc().indptr)\n",
    "item_popularity_encoded = np.sort(item_popularity_encoded)\n",
    "\n",
    "tar_users = target_users[\"UserID\"].astype(int)\n",
    "topPop_encoded = item_popularity_encoded[-10:]\n",
    "\n",
    "submission = []\n",
    "\n",
    "print(np.unique(df[\"UserID\"].values))\n",
    "\n",
    "for index, user in enumerate(tar_users):\n",
    "    if (user not in df[\"UserID\"].values):\n",
    "        item_list_encoded = topPop_encoded\n",
    "    else:\n",
    "        item_list_encoded = hybrid.recommend(user2user_encoded[user])[:10]\n",
    "    item_list = []\n",
    "    for item_encoded in item_list_encoded:\n",
    "        item_list.append(item_encoded2item[item_encoded])\n",
    "    submission.append((user, item_list))\n",
    "\n",
    "\n",
    "def write_submission(submissions):\n",
    "    with open(\"./submission_hybrid_combo_script.csv\", \"w\") as f:\n",
    "        f.write(\"user_id,item_list\\n\")\n",
    "        for user_id, items in submissions:\n",
    "            f.write(f\"{user_id},{' '.join([str(item) for item in items])}\\n\")\n",
    "            \n",
    "write_submission(submission)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "RecSysFramework",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
